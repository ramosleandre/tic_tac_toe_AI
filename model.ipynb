{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from conversion import CSVToTensor\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = 9\n",
    "        self.output_size = 9\n",
    "        self.hidden_size = 1*27\n",
    "        self.middle_size = 2*27\n",
    "\n",
    "        self.x0 = None\n",
    "        self.x1 = None\n",
    "        self.x2 = None\n",
    "        self.x3 = None\n",
    "\n",
    "        self.W1 = nn.Parameter(torch.randn(self.input_size, self.hidden_size))\n",
    "        self.b1 = nn.Parameter(torch.randn(self.hidden_size))\n",
    "        # self.W2 = nn.Parameter(torch.randn(self.hidden_size, self.hidden_size))\n",
    "        # self.b2 = nn.Parameter(torch.randn(self.hidden_size))\n",
    "        self.W3 = nn.Parameter(torch.randn(self.hidden_size, self.middle_size))\n",
    "        self.b3 = nn.Parameter(torch.randn(self.middle_size))\n",
    "        self.W4 = nn.Parameter(torch.randn(self.middle_size, self.hidden_size))\n",
    "        self.b4 = nn.Parameter(torch.randn(self.hidden_size))\n",
    "        self.W5 = nn.Parameter(torch.randn(self.hidden_size, self.output_size))\n",
    "        self.b5 = nn.Parameter(torch.randn(self.output_size))\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.dropout = nn.Dropout(0.3)\n",
    "        self.crossloss = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x0 = x\n",
    "        self.x1 = x @ self.W1 + self.b1\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        # self.x3 = self.x2 @ self.W2 + self.b2\n",
    "        # self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.x2 @ self.W3 + self.b3\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        self.x7 = self.x6 @ self.W4 + self.b4\n",
    "        self.x8 = self.relu(self.x7)\n",
    "        self.x9 = self.x8 @ self.W5 + self.b5\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        return self.x9\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        dataloader = CSVToTensor(file_path)\n",
    "        dataloader.create_all_tensor()\n",
    "        dataset = dataloader.create_a_dataset()\n",
    "\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        self.train_data, self.val_data = random_split(dataset, [train_size, val_size])\n",
    "        self.train_data = DataLoader(self.train_data, batch_size=16, shuffle=True)\n",
    "        self.val_data = DataLoader(self.val_data, batch_size=16, shuffle=True)\n",
    "\n",
    "    def train_model(self, epochs):\n",
    "        self.to(self.device)\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for src, trg in self.train_data:\n",
    "                src = src.to(self.device)\n",
    "                trg = trg.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.forward(src)\n",
    "                loss = self.crossloss(output, trg.argmax(dim=1))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            avg_loss = epoch_loss / len(self.train_data)\n",
    "            print(f\"Epoch: {epoch}, Loss: {avg_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     model = Model()\n",
    "#     # choose the dataset file path\n",
    "#     model.load_data('./Datasets/tic_tac_toe_500_games.csv')\n",
    "#     # choose the number of epochs\n",
    "#     with torch.no_grad():\n",
    "#         model.W1.copy_(torch.zeros(model.input_size, model.hidden_size))\n",
    "#         model.b1.copy_(torch.ones(model.hidden_size))\n",
    "#         model.W2.copy_(torch.zeros(model.hidden_size, model.output_size))\n",
    "#         model.b2.copy_(torch.ones(model.output_size))\n",
    "#     model.train_model(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Weight Calculation by Human Reflection\n",
    "\n",
    "The following three cells demonstrate how a neural network's weights can be manually calculated to understand how updates affect the network. This process is aimed at providing educational insight into debugging neural networks.\n",
    "\n",
    "We consider 6 possible input scenarios and manually calculate the appropriate weights to ensure correctness for each scenario without causing errors in others.\n",
    "\n",
    "(Note: This is purely for educational purposes to understand debugging and does not alter the models themselves.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "-----------------\n",
      "tensor([[1., 1., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "-----------------\n",
      "tensor([[0., 1., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "-----------------\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "-----------------\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "-----------------\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "mytensor1 = torch.tensor([[1,0,1],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "mytensor1 = mytensor1.reshape(1,9)\n",
    "outtensor1 = torch.tensor([[0,2,0,0,0,0,0,0,0]], dtype=torch.float32)\n",
    "\n",
    "print(mytensor1.view(3,3))\n",
    "print(\"-----------------\")\n",
    "\n",
    "mytensor2 = torch.tensor([[1,1,0],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "mytensor2 = mytensor2.reshape(1,9)\n",
    "outtensor2 = torch.tensor([[0,0,2,0,0,0,0,0,0]], dtype=torch.float32)\n",
    "\n",
    "print(mytensor2.view(3,3))\n",
    "print(\"-----------------\")\n",
    "\n",
    "mytensor3 = torch.tensor([[0,1,1],[0,0,0],[0,0,0]], dtype=torch.float32)\n",
    "mytensor3 = mytensor3.reshape(1,9)\n",
    "outtensor3 = torch.tensor([[2,0,0,0,0,0,0,0,0]], dtype=torch.float32)\n",
    "\n",
    "print(mytensor3.view(3,3))\n",
    "print(\"-----------------\")\n",
    "\n",
    "mytensor4 = torch.tensor([[1,0,0],[0,0,0],[1,0,0]], dtype=torch.float32)\n",
    "mytensor4 = mytensor4.reshape(1,9)\n",
    "outtensor4 = torch.tensor([[0,0,0,2,0,0,0,0,0]], dtype=torch.float32)\n",
    "\n",
    "print(mytensor4.view(3,3))\n",
    "print(\"-----------------\")\n",
    "\n",
    "mytensor5 = torch.tensor([[1,0,0],[1,0,0],[0,0,0]], dtype=torch.float32)\n",
    "mytensor5 = mytensor5.reshape(1,9)\n",
    "outtensor5 = torch.tensor([[0,0,0,0,0,0,2,0,0]], dtype=torch.float32)\n",
    "\n",
    "print(mytensor5.view(3,3))\n",
    "print(\"-----------------\")\n",
    "\n",
    "mytensor6 = torch.tensor([[0,0,0],[1,0,0],[1,0,0]], dtype=torch.float32)\n",
    "mytensor6 = mytensor6.reshape(1,9)\n",
    "outtensor6 = torch.tensor([[2,0,0,0,0,0,0,0,0]], dtype=torch.float32)\n",
    "\n",
    "print(mytensor6.view(3,3))\n",
    "print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (27) must match the size of tensor b (9) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m M\u001b[38;5;241m.\u001b[39mW1\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mzeros(M\u001b[38;5;241m.\u001b[39minput_size, M\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[1;32m      3\u001b[0m M\u001b[38;5;241m.\u001b[39mb1\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mzeros(M\u001b[38;5;241m.\u001b[39mhidden_size))\n\u001b[0;32m----> 4\u001b[0m \u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m M\u001b[38;5;241m.\u001b[39mb2\u001b[38;5;241m.\u001b[39mcopy_(torch\u001b[38;5;241m.\u001b[39mzeros(M\u001b[38;5;241m.\u001b[39moutput_size))\n\u001b[1;32m      7\u001b[0m M\u001b[38;5;241m.\u001b[39mW1[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (27) must match the size of tensor b (9) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    M.W1.copy_(torch.zeros(M.input_size, M.hidden_size))\n",
    "    M.b1.copy_(torch.zeros(M.hidden_size))\n",
    "    M.W2.copy_(torch.zeros(M.hidden_size, M.output_size))\n",
    "    M.b2.copy_(torch.zeros(M.output_size))\n",
    "\n",
    "    M.W1[0, 1] = 2\n",
    "    M.W1[0, 0] = -2\n",
    "    M.W1[0, 3] = 2\n",
    "\n",
    "    M.W1[1,1] = -2\n",
    "    M.W1[1, 2] = 2\n",
    "    M.W1[1, 3] = -2\n",
    "        \n",
    "    M.W1[2, 0] = 2\n",
    "    M.W1[2, 2] = -2\n",
    "    M.W1[2 , 3] = - 2\n",
    "    \n",
    "    M.W1[3, 6] = 2\n",
    "    M.W1[3 ,3] = -2\n",
    "    M.W1[3, 1] = -2\n",
    "    \n",
    "    M.W1[6, 1] = -2\n",
    "    M.W1[6, 6] = -2\n",
    "    M.W1[6, 0] = 2\n",
    "    M.W2[0:M.output_size , 0:M.output_size] = torch.eye(M.output_size)\n",
    "print(M.W1)\n",
    "# print(M.b1)\n",
    "# print(M.W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 1., 0., 0., 1., 0., 0.]])\n",
      "----------------\n",
      "tensor([[2., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<AddBackward0>)\n",
      "----------------\n",
      "Excepted \n",
      "tensor([[0., 0., 2., 0., 0., 0., 0., 0., 0.]])\n",
      "----------------\n",
      "Output argmax :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = M.forward(mytensor6)\n",
    "x0 = M.x0\n",
    "x1 = M.x1\n",
    "x2 = M.x2\n",
    "x3 = M.x3\n",
    "\n",
    "print(x0)\n",
    "print(\"----------------\")\n",
    "print(output)\n",
    "print(\"----------------\")\n",
    "print(\"Excepted \")\n",
    "print(outtensor2)\n",
    "print(\"----------------\")\n",
    "print(\"Output argmax :\")\n",
    "output.argmax()\n",
    "# loss = mytensor2 - outtensor2\n",
    "# loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda in0, out0: out0-in0\n",
    "# example of how work lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Weight Calculation by Machine Reflection\n",
    "\n",
    "The following three cells demonstrate how a neural network's weights can be calculated using machine reflection to understand how updates affect the network. This process is aimed at providing educational insight into debugging neural networks.\n",
    "\n",
    "For each line of code, we'll reflect on the machine's operations to ensure correctness. We consider 6 possible input scenarios and calculate the appropriate weights to ensure they are correct for each scenario without causing errors in others.\n",
    "\n",
    "The values are manually updated based on the results of the backpropagation provided by the model.\n",
    "\n",
    "The dataset for training will be composed only of the 6 tensor that you seen above and will be in the ./Datasets/debug.csv\n",
    "\n",
    "(Note: This is purely for educational purposes to understand debugging through machine reflection and does not alter the models themselves.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for training,\n",
    "# we don't split the data because we will evaluate manually\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "path = './Datasets/debug.csv'\n",
    "loader = CSVToTensor(path)\n",
    "loader.create_all_tensor()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_tensor, output_tensor):\n",
    "        self.input_tensor = input_tensor\n",
    "        self.output_tensor = output_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data = self.input_tensor[idx]\n",
    "        output_data = self.output_tensor[idx]\n",
    "        return input_data, output_data\n",
    "\n",
    "input_tensor = loader.game_tensor\n",
    "output_tensor = loader.prediction_tensor\n",
    "\n",
    "combined_dataset = CustomDataset(input_tensor, output_tensor)\n",
    "\n",
    "combined_dataloader = DataLoader(combined_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src :  tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0.]]) \n",
      "trg :  tensor([[0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "        [0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [2., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for src, trg in combined_dataloader:\n",
    "    print(\"src : \" , src, \"\\ntrg : \" , trg)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.enable_grad():\n",
    "    M.W1 = nn.Parameter(torch.randn(M.input_size, M.hidden_size))\n",
    "    M.b1 = nn.Parameter(torch.randn(M.hidden_size))\n",
    "    # M.W2 = nn.Parameter(torch.randn(M.hidden_size, M.hidden_size))\n",
    "    # M.b2 = nn.Parameter(torch.randn(M.hidden_size))\n",
    "    M.W3 = nn.Parameter(torch.randn(M.hidden_size, M.middle_size))\n",
    "    M.b3 = nn.Parameter(torch.randn(M.middle_size))\n",
    "    M.W4 = nn.Parameter(torch.randn(M.middle_size, M.hidden_size))\n",
    "    M.b4 = nn.Parameter(torch.randn(M.hidden_size))\n",
    "    M.W5 = nn.Parameter(torch.randn(M.hidden_size, M.output_size))\n",
    "    M.b5 = nn.Parameter(torch.randn(M.output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model and debug him"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range (240):\n",
    "    for src, trg in combined_dataloader:\n",
    "        M.optimizer.zero_grad()\n",
    "\n",
    "        output = M.forward(src)\n",
    "\n",
    "        # loss = torch.pow(output - trg, 2).sum().sqrt()\n",
    "        # loss = torch.nn.functional.mse_loss(output, trg)\n",
    "        loss = M.crossloss(output, trg.argmax(dim=1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        M.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss :\t 259.7158508300781\n",
      "learning rate :  0.001\n",
      "input :\t tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0.]])\n",
      "target : tensor([[0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 2., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 2., 0., 0.],\n",
      "        [0., 2., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [2., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [2., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "output : tensor([[ 403.5565,  -23.2329, -123.1361, -132.7495,  -60.0375, -245.1788,\n",
      "         -241.0100,   48.6205, -165.5857],\n",
      "        [ 320.4021,  -40.1247, -140.8801,   -2.1158,  -81.3735, -194.7916,\n",
      "         -154.6671,   69.7379, -154.3593],\n",
      "        [  92.2327,   30.5439, -145.9053,   28.3069,  -19.4615, -214.6596,\n",
      "         -219.6817,    6.5259, -119.1038],\n",
      "        [  81.9747,   -7.8711, -237.9186,  -31.6092,  -51.5253, -315.7138,\n",
      "         -350.0272,   35.9161, -197.0858],\n",
      "        [-171.7108,  135.6135,  -16.0944,  116.5197,  -76.4997, -260.4041,\n",
      "         -222.7030,   32.7617, -132.2342],\n",
      "        [ 107.3268,  -53.9242, -186.0642,  -50.0476,  -94.9541, -216.9098,\n",
      "         -319.1335,   60.1400, -161.8181]], grad_fn=<AddBackward0>)\n",
      "\n",
      "W1 grad :\t tensor([[-2.8142e+03,  0.0000e+00,  8.8691e+03,  0.0000e+00, -2.2532e+03,\n",
      "          8.8253e+03,  1.4990e+04,  0.0000e+00,  1.5299e+04,  1.6020e+03,\n",
      "         -4.6551e+03,  1.2177e+04, -6.8589e+03, -2.9765e+03,  1.8018e+04,\n",
      "          0.0000e+00,  0.0000e+00,  2.1493e+04,  0.0000e+00,  3.0153e+03,\n",
      "          3.2936e+04, -5.1514e+02,  9.2258e+03,  6.1092e+03,  1.0787e+02,\n",
      "         -6.5044e+03, -9.0753e+02],\n",
      "        [-8.4237e+02,  0.0000e+00,  7.6503e+03,  0.0000e+00, -1.2257e+03,\n",
      "          4.6850e+03,  7.5427e+03, -7.9692e+03,  4.7432e+03,  1.6276e+03,\n",
      "          0.0000e+00,  6.6494e+03, -4.4849e+03,  0.0000e+00,  6.5660e+03,\n",
      "         -8.8651e+02,  0.0000e+00,  1.4400e+04,  0.0000e+00,  5.0657e+02,\n",
      "          1.9748e+04, -1.3423e+03,  2.0347e+03,  3.7488e+03,  0.0000e+00,\n",
      "         -3.2828e+03,  0.0000e+00],\n",
      "        [-2.9531e+03,  0.0000e+00,  6.1034e+03,  0.0000e+00,  0.0000e+00,\n",
      "          4.7806e+03,  7.2132e+03, -7.9692e+03,  4.1177e+03,  0.0000e+00,\n",
      "         -4.1062e+03,  1.8179e+03,  5.5517e+02, -3.4624e+02,  7.4174e+03,\n",
      "         -8.8651e+02,  0.0000e+00,  1.3747e+04,  0.0000e+00,  5.0657e+02,\n",
      "          1.2871e+04, -1.8574e+03,  7.9176e+02,  4.8164e+03,  1.0787e+02,\n",
      "         -2.7623e+03,  0.0000e+00],\n",
      "        [ 1.1528e+03,  1.2972e+03,  1.9005e+03,  4.0003e+03,  0.0000e+00,\n",
      "          3.9867e+03,  5.7883e+03,  0.0000e+00,  5.6507e+02,  0.0000e+00,\n",
      "          4.4764e+03,  2.7315e+03, -1.9290e+03,  0.0000e+00,  5.2075e+03,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  6.8425e+03,\n",
      "          4.7082e+03,  0.0000e+00,  2.3778e+03,  6.0902e+03,  0.0000e+00,\n",
      "         -4.5503e+02,  4.2532e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.7158e+02,  1.2972e+03,  0.0000e+00,  4.0003e+03, -1.0275e+03,\n",
      "          1.1325e+03,  6.5820e+03,  0.0000e+00, -2.0193e+03, -2.5562e+01,\n",
      "          3.9276e+03,  3.3517e+03,  0.0000e+00, -2.6302e+03,  4.3085e+03,\n",
      "          0.0000e+00,  0.0000e+00,  6.0957e+03,  0.0000e+00,  9.8578e+03,\n",
      "          8.4480e+03,  0.0000e+00,  2.8550e+03,  4.7022e+03,  0.0000e+00,\n",
      "         -9.6898e+02,  5.1608e+03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "W1 grad max :\t 32935.74609375\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nloss :\\t\", loss.item())\n",
    "print(\"learning rate : \", M.optimizer.param_groups[0]['lr'])\n",
    "# print (\"source :\\t\", src)\n",
    "print (\"input :\\t\", M.x0)\n",
    "print (\"target :\", trg)\n",
    "print (\"output :\", output)\n",
    "print (\"\\nW1 grad :\\t\", M.W1.grad)\n",
    "print ('W1 grad max :\\t', M.W1.grad.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a backup of the model parameters\n",
    "W1_backup = M.W1\n",
    "W2_backup = M.W2\n",
    "b1_backup = M.b1\n",
    "b2_backup = M.b2\n",
    "loss_backup = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss backup :  tensor(9.0931, grad_fn=<NllLossBackward0>)\n",
      "----------------\n",
      "Parameter containing:\n",
      "tensor([[-8.3823e-01,  1.6689e+00, -4.8720e-01,  6.5497e-01,  2.5154e+00,\n",
      "          4.9060e-01, -8.4316e-01,  4.2954e-01, -2.7034e-01,  5.9296e-01,\n",
      "          1.2493e-01,  8.7014e-01,  8.9828e-01, -5.9537e-01, -7.6154e-01,\n",
      "         -5.7165e-01, -1.8796e+00,  2.3637e-01, -3.7898e-01,  2.3082e-01,\n",
      "         -4.9364e-01,  4.1974e-01, -5.6861e-01,  2.2960e+00,  1.2559e-01,\n",
      "         -3.1320e-01,  1.9170e-01,  8.8043e-01, -1.2137e+00,  2.8339e-01,\n",
      "          1.2445e+00,  7.9507e-01,  1.9056e-01, -1.2515e-01, -3.3326e-02,\n",
      "         -2.8241e-01, -1.3753e+00, -1.4740e+00, -5.4155e-01,  8.6255e-01,\n",
      "          6.7343e-01,  9.6610e-01, -1.9353e-01,  5.9533e-01, -2.4593e-02,\n",
      "          2.4699e-01,  1.0093e+00,  6.3805e-01, -3.5799e-01, -4.7814e-01,\n",
      "          3.4427e-01,  1.3501e+00, -2.1410e+00,  1.6910e+00],\n",
      "        [-6.6460e-01, -8.4688e-01,  4.0256e-01,  1.5847e+00,  3.1539e-01,\n",
      "          2.3975e+00,  1.1412e-01,  3.1499e-01,  2.3593e-02,  3.5971e-01,\n",
      "         -1.3108e+00,  1.0931e-01,  3.3307e-02,  9.6379e-01,  1.2591e-01,\n",
      "         -1.6758e+00,  5.1605e-01,  9.6976e-01, -2.2545e+00, -4.1159e-01,\n",
      "         -7.7602e-02, -1.2511e+00, -7.1330e-01,  1.8175e-01, -9.4765e-02,\n",
      "          4.9322e-01, -6.9295e-01,  5.6340e-01, -2.7721e-02,  1.7506e+00,\n",
      "          1.4836e+00, -1.3072e+00, -8.9574e-01,  2.3447e-01,  1.0722e+00,\n",
      "         -1.8531e-01,  7.2108e-03, -1.5418e+00,  2.1745e+00, -7.0577e-01,\n",
      "          1.6619e+00, -9.5954e-01, -1.3482e+00, -1.3141e+00,  5.5533e-01,\n",
      "         -8.7859e-01,  2.7585e-01, -5.4577e-01,  6.6331e-02,  2.2888e+00,\n",
      "          9.9001e-01,  1.5194e-01, -2.0699e-02, -2.2329e-01],\n",
      "        [ 3.4903e-01, -2.1449e-02, -4.7037e-01,  7.9326e-01,  1.8387e+00,\n",
      "         -2.6498e+00, -2.4216e-01,  2.5576e+00, -9.0849e-01,  1.7628e-01,\n",
      "         -1.3602e+00,  1.2349e+00, -6.5555e-01, -1.3803e+00,  3.3653e-02,\n",
      "         -1.7935e+00, -1.3297e+00, -8.6455e-01,  6.8963e-01,  1.4447e+00,\n",
      "         -9.9184e-01,  2.4043e-01, -9.4962e-02,  2.3412e-01, -8.2855e-01,\n",
      "         -4.2948e-01,  5.3337e-01,  1.3946e-01, -3.5106e-01, -1.7389e-01,\n",
      "         -2.4510e+00,  8.2698e-02, -9.9155e-02, -1.5664e+00, -4.3068e-01,\n",
      "          4.0747e-01, -8.1124e-01, -7.6452e-01, -1.0853e+00, -7.5866e-01,\n",
      "          1.1103e+00,  4.6843e-01,  6.5425e-01, -1.2669e+00,  1.7906e-01,\n",
      "         -2.5283e-01, -3.9621e-01,  1.0629e+00, -8.7250e-01, -9.0932e-01,\n",
      "         -8.4396e-01, -6.5533e-01, -8.5792e-01,  1.1606e+00],\n",
      "        [-1.6453e+00,  1.8150e-01, -3.4164e-01,  4.4468e-01,  3.8181e-02,\n",
      "          1.1372e-01,  1.8005e+00, -6.2892e-01,  1.2729e+00,  9.6076e-01,\n",
      "         -1.6169e-01, -3.2173e-01,  8.4362e-01, -8.9094e-01, -1.6680e+00,\n",
      "          3.8946e-02,  3.2998e-01,  7.1182e-01, -1.6539e+00, -1.9209e+00,\n",
      "          3.4836e-01,  2.4106e+00, -4.0461e-01,  1.0496e+00, -6.6952e-01,\n",
      "         -1.3137e+00,  1.3854e-01,  3.3900e-01, -6.7007e-02,  3.7822e-01,\n",
      "         -8.1248e-01, -7.9307e-01, -1.4126e-02,  1.2489e+00, -1.9350e+00,\n",
      "          1.3114e-01, -6.1566e-01, -1.4881e+00,  8.2886e-01, -3.0626e+00,\n",
      "         -2.5468e-01,  2.3025e+00, -5.8402e-01, -1.6150e-01, -3.7025e-01,\n",
      "          1.2743e-01,  5.0212e-02, -1.0975e-01, -2.9908e-01,  6.7819e-02,\n",
      "         -3.3873e-01, -7.7579e-01,  6.1422e-01,  1.1475e+00],\n",
      "        [-2.5523e-03, -5.1148e-01, -5.1512e-01,  3.0595e-01, -9.3809e-01,\n",
      "          2.4836e-01, -2.3732e-01,  1.4116e+00, -4.8629e-02, -1.6738e+00,\n",
      "         -9.9083e-02,  1.4474e+00,  9.6649e-02,  4.4019e-01,  3.1640e-01,\n",
      "          1.0158e+00, -2.2691e-01, -1.4904e+00, -7.4860e-01,  8.6731e-02,\n",
      "          1.7218e-01, -7.6989e-01,  4.5127e-01,  9.2107e-01, -4.1569e-02,\n",
      "          5.6829e-01, -3.4462e-01, -1.0594e+00,  1.0595e+00, -1.8106e-01,\n",
      "         -3.8572e-01, -3.0240e-01, -1.9384e-01,  2.1080e+00,  1.1021e+00,\n",
      "         -7.6677e-01, -5.5662e-01, -1.3629e+00, -5.3890e-01,  5.5644e-02,\n",
      "          8.4770e-01,  1.0548e+00,  5.3460e-01, -1.4796e+00, -1.8537e-01,\n",
      "          7.5849e-02, -7.9333e-01, -1.4562e+00, -2.2286e-01, -2.4774e-01,\n",
      "         -1.4763e-01, -1.2624e+00, -1.2157e+00, -3.9861e-01],\n",
      "        [-3.5901e-01, -8.5161e-01,  6.5085e-01, -3.6483e-01,  9.5064e-01,\n",
      "          5.6201e-01,  3.4897e-01, -1.0258e+00, -8.3937e-01,  9.6301e-01,\n",
      "         -2.1866e-01,  1.6704e+00, -5.2245e-01,  1.5190e+00,  1.0020e+00,\n",
      "         -1.5087e+00, -5.2092e-01,  5.1245e-01, -6.4001e-01, -1.1449e+00,\n",
      "         -1.3547e+00, -6.2641e-01, -1.2969e+00,  6.3979e-01, -8.1257e-01,\n",
      "         -1.2390e+00, -7.0937e-01,  4.7904e-01,  1.1225e+00, -7.3739e-01,\n",
      "          7.1109e-02,  1.3120e+00, -5.0687e-01,  7.3855e-01, -1.2651e+00,\n",
      "          4.3689e-01,  2.4363e-01,  4.6140e-01,  6.6146e-01, -5.4316e-01,\n",
      "          3.6287e-01,  1.1004e+00,  5.4228e-02,  3.2318e-01,  1.0020e+00,\n",
      "         -2.3799e-01, -6.7534e-01,  1.4923e+00, -2.1231e+00, -6.2944e-01,\n",
      "          1.8557e+00,  3.1323e-01,  7.6860e-01, -9.2076e-01],\n",
      "        [-1.6214e+00,  9.8254e-01,  1.5681e+00,  2.6887e-01, -4.4392e-01,\n",
      "         -4.5048e-02,  2.5459e+00, -5.6643e-01, -6.5475e-01, -7.2155e-01,\n",
      "         -4.3524e-01, -1.0935e+00, -5.6847e-01, -5.9729e-01,  9.2708e-03,\n",
      "         -1.2386e+00, -2.4947e+00, -9.5945e-01, -2.1546e-01, -1.3005e-01,\n",
      "          5.4021e-02,  1.2021e+00, -4.7458e-01,  1.8558e+00,  2.4907e-01,\n",
      "          4.9122e-01, -3.2534e+00,  1.1358e+00, -9.0559e-02,  5.8637e-02,\n",
      "         -1.3627e+00,  1.0535e+00, -3.8228e-01, -2.5375e+00, -1.4748e+00,\n",
      "          1.0243e+00, -1.0773e+00,  1.2605e-01,  1.4047e+00, -5.9416e-01,\n",
      "         -8.9988e-02, -2.0012e+00,  6.0454e-01, -1.2530e+00,  1.9629e+00,\n",
      "          4.3312e-01, -2.3586e+00, -1.1130e+00, -8.9510e-01, -1.8478e-01,\n",
      "         -1.1753e+00, -1.2514e+00, -6.4977e-02,  6.8781e-01],\n",
      "        [ 9.7908e-01,  4.9116e-01, -1.0666e+00, -1.9278e-01, -2.8611e-01,\n",
      "          1.2574e+00, -1.1061e-01,  9.3805e-01,  6.4427e-01,  3.3407e-01,\n",
      "          6.2763e-01,  3.7779e-01,  1.5569e+00, -2.4954e+00, -1.9289e+00,\n",
      "         -3.7132e-01,  4.0103e-01,  1.1725e-01, -1.6545e+00,  2.4694e-01,\n",
      "         -1.0675e+00, -8.0323e-01, -4.6561e-01,  3.1322e-01, -5.1483e-01,\n",
      "         -4.6128e-01,  9.0175e-03,  1.4777e+00, -1.5251e-03,  9.3310e-01,\n",
      "          8.3741e-01, -1.3965e+00,  1.2506e+00,  1.8903e+00, -4.6347e-01,\n",
      "         -1.5168e+00, -7.8046e-01,  1.7072e+00, -2.6115e-01,  1.0040e+00,\n",
      "          1.1811e+00, -3.6964e-01, -1.3322e+00,  6.5673e-01,  1.3012e+00,\n",
      "          4.1416e-02, -1.1924e+00, -7.0860e-01, -6.6807e-01, -3.2340e-01,\n",
      "          5.7884e-01,  6.7682e-01,  2.3435e+00,  2.0791e+00],\n",
      "        [-5.0478e-01, -2.5871e-02,  2.8094e-01, -8.9612e-01,  1.2911e+00,\n",
      "         -6.4980e-01,  2.9164e-01,  6.8893e-01,  1.0984e+00,  1.1818e+00,\n",
      "         -2.9780e-01,  6.5027e-01,  1.4295e+00, -1.8910e+00, -3.7842e-02,\n",
      "          2.4127e-01, -8.7270e-01,  4.4086e-01,  9.7100e-01, -1.1460e+00,\n",
      "         -2.9220e-01, -2.0603e-02, -9.4971e-01,  9.5894e-02,  1.9986e-01,\n",
      "         -1.0243e+00,  1.0724e+00,  2.4239e-01, -1.1729e+00,  5.7787e-01,\n",
      "         -1.0899e+00,  9.3297e-01, -5.5705e-01,  5.0085e-01, -1.3523e+00,\n",
      "          6.1371e-01, -4.3157e-01,  8.8847e-01, -1.0235e+00,  2.9340e-01,\n",
      "          1.7750e+00, -3.2136e-01, -8.1434e-01,  3.2428e-01,  5.1158e-01,\n",
      "          1.8179e+00, -9.3871e-02, -1.8710e+00, -7.4900e-01,  1.2688e+00,\n",
      "         -1.3668e-01,  5.8778e-01, -1.4146e+00,  1.5413e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5208, -1.8295, -0.0465, -0.1626,  0.6909,  0.5114, -0.4445,  1.5309,\n",
      "         0.0942, -0.0227, -0.3947,  0.0287,  0.0862,  2.3347,  0.3888,  0.3211,\n",
      "         0.8380,  0.5966, -0.6564,  0.1545,  0.4072,  1.0891, -0.5393, -0.9126,\n",
      "        -1.4517,  0.0054,  0.5338, -0.5826, -1.4960, -0.0863,  1.6461, -0.2541,\n",
      "        -1.6794, -1.0597, -0.7160, -1.3555, -0.0255,  1.0410,  1.7725,  0.6134,\n",
      "        -1.1456,  1.4357,  2.1056,  0.0474, -0.3141,  0.1671, -0.4523,  0.4623,\n",
      "        -0.5742,  0.3702, -0.7501,  1.3639,  0.2914,  0.9906],\n",
      "       requires_grad=True)\n",
      "----------------\n",
      "Parameter containing:\n",
      "tensor([[-4.5262e-01, -1.5555e-01,  2.4818e-01,  3.3826e-01, -1.3340e+00,\n",
      "          7.4312e-01,  4.0508e-01,  7.8052e-01, -9.1872e-01],\n",
      "        [ 5.6168e-01,  1.7789e-01,  1.3091e+00, -8.0224e-01,  1.1273e-01,\n",
      "         -7.9104e-02,  1.0453e+00, -2.4484e-02, -3.3270e-02],\n",
      "        [ 4.1110e-01, -2.1144e-01,  1.0064e+00,  1.2168e+00,  1.5498e+00,\n",
      "         -1.7630e+00, -1.3064e+00, -2.3834e-01, -7.6509e-01],\n",
      "        [ 1.3208e+00,  1.5938e+00,  1.9118e+00, -2.7067e+00, -4.3393e-01,\n",
      "         -1.8573e+00,  2.9834e-01, -1.3214e-01, -4.4259e-01],\n",
      "        [ 6.2461e-02,  4.2460e-01, -1.0842e+00, -4.7403e-01, -7.9815e-01,\n",
      "         -8.8551e-01, -9.1188e-01, -2.9338e-01,  8.0567e-01],\n",
      "        [ 2.4825e+00,  1.5381e-01,  2.0250e+00,  1.1902e+00,  4.9369e-01,\n",
      "         -9.6878e-01, -3.8022e-01, -1.1716e-01, -1.2586e-02],\n",
      "        [ 8.5719e-01, -6.4352e-01,  1.0434e+00, -6.6453e-01, -2.0234e+00,\n",
      "          7.2860e-01,  9.1353e-02, -6.6248e-01,  8.2503e-01],\n",
      "        [ 1.4097e+00,  9.8054e-01, -1.5762e+00, -1.5432e-01, -2.7584e-01,\n",
      "          2.2436e-01, -5.1713e-01, -9.5499e-01, -4.1278e-01],\n",
      "        [ 6.7382e-01, -8.1827e-01,  6.4745e-01, -1.3507e+00, -6.3741e-01,\n",
      "          5.8074e-01, -2.5183e+00, -4.5350e-02,  6.3568e-01],\n",
      "        [ 8.4815e-01,  9.4174e-01, -1.0872e+00,  2.4284e+00,  7.6596e-01,\n",
      "          1.4036e+00, -2.3480e+00,  1.4754e+00,  1.9490e+00],\n",
      "        [-9.5206e-01, -1.2538e+00, -1.9943e-01,  1.7117e+00,  4.2801e-01,\n",
      "         -2.1302e+00, -3.2535e-01, -2.6611e+00, -9.0842e-01],\n",
      "        [-1.8475e-01,  1.1370e+00,  2.3323e+00,  2.4376e-01,  7.1849e-01,\n",
      "          1.7406e+00,  8.2544e-01, -7.2267e-01,  3.0521e-01],\n",
      "        [ 1.0362e+00,  4.4526e-01,  2.0173e+00, -1.3886e+00, -1.5103e+00,\n",
      "          4.4150e-01,  1.8807e+00, -1.1162e+00, -6.1979e-01],\n",
      "        [-3.3883e-01,  2.5571e+00,  1.7410e+00,  1.0528e-01, -5.9852e-01,\n",
      "         -3.4308e-01,  1.6155e+00,  4.4568e-01, -4.1078e-01],\n",
      "        [-2.4326e+00, -1.6703e-02,  2.0249e+00,  7.9379e-01,  9.1101e-01,\n",
      "         -1.1570e+00, -1.0345e+00,  2.6326e-01, -1.7322e-01],\n",
      "        [-1.7113e+00,  9.6222e-01,  2.1023e-01, -2.4014e-01,  6.9885e-01,\n",
      "         -3.5083e-01, -1.3303e+00,  2.8357e+00, -7.3368e-01],\n",
      "        [ 4.5623e-01, -1.8111e+00,  1.5433e+00,  1.4988e+00,  9.0797e-01,\n",
      "          2.5851e+00,  7.1709e-01, -8.1164e-01,  1.7752e+00],\n",
      "        [ 6.4242e-01,  8.1554e-04,  4.9831e-01, -2.0885e+00, -6.6215e-01,\n",
      "         -1.1951e+00,  6.1495e-01,  1.1356e+00,  1.0293e+00],\n",
      "        [ 5.4591e-01,  5.3451e-01,  3.8502e-01,  6.8611e-01,  3.0236e-01,\n",
      "          7.6640e-01,  5.9919e-01, -3.2656e-01, -1.6503e+00],\n",
      "        [ 3.3966e-01, -5.7247e-01,  7.5260e-01, -2.7992e-01, -1.4349e+00,\n",
      "         -1.3221e+00,  1.0707e+00, -7.9157e-01,  7.7291e-01],\n",
      "        [-5.5939e-01,  2.0282e-01, -1.2364e+00, -2.1819e+00,  7.0292e-01,\n",
      "          8.9377e-01,  1.3315e-01, -1.8538e-01, -3.7322e-01],\n",
      "        [-4.3413e-01, -9.2734e-03,  1.9205e+00,  6.9817e-01,  4.8507e-01,\n",
      "         -4.3899e-02, -2.6785e-01,  4.0311e-01, -3.3278e-01],\n",
      "        [-2.3540e+00, -7.6168e-01,  1.0093e+00,  1.7682e+00, -4.4766e-01,\n",
      "          1.4227e+00,  6.6492e-01,  6.7622e-01, -1.7000e+00],\n",
      "        [ 2.4829e-01,  2.7613e+00, -1.4093e+00,  3.3373e-01,  1.2721e+00,\n",
      "         -9.9422e-01,  3.3089e-01,  1.0639e+00, -1.6874e-01],\n",
      "        [-1.8169e-02,  1.6014e-02, -1.6082e-01,  3.5649e-01, -8.5999e-03,\n",
      "          8.1813e-01, -3.2856e-01, -1.0251e-01, -1.4781e+00],\n",
      "        [ 2.8145e-01, -1.0182e+00,  1.7573e+00,  1.2089e+00, -5.1964e-01,\n",
      "          2.8846e-01,  1.7833e+00,  2.4810e+00, -2.2601e-01],\n",
      "        [ 3.7825e-01,  3.8232e-02, -6.3015e-01,  2.7403e-02,  8.9856e-01,\n",
      "          1.1849e+00,  6.2949e-01,  1.4791e+00, -1.5645e+00],\n",
      "        [ 8.9032e-01, -1.6940e+00, -1.0322e+00, -3.1865e+00,  1.5186e-01,\n",
      "         -1.6297e+00,  2.6368e-01, -2.8565e+00, -1.0274e+00],\n",
      "        [-9.2217e-01, -1.5648e+00, -3.0521e-03,  8.3000e-01, -5.2860e-01,\n",
      "         -8.0378e-01,  4.1661e-01,  1.8614e-01, -4.8052e-01],\n",
      "        [-5.6775e-01,  1.7326e+00,  1.1724e+00,  1.4391e+00,  2.1559e-01,\n",
      "         -1.0503e+00,  1.7483e-01,  2.7353e-01, -2.8270e-01],\n",
      "        [-4.9868e-01, -1.5354e-01,  6.5594e-01, -2.2413e+00, -1.4622e+00,\n",
      "         -6.7614e-01,  1.7665e+00,  1.0464e+00,  1.0744e+00],\n",
      "        [-1.4754e-01, -9.0211e-01,  6.3157e-02, -2.4081e-01,  1.0004e+00,\n",
      "          2.9390e-01,  7.8508e-01,  7.9425e-01,  6.6600e-03],\n",
      "        [ 1.0309e+00, -4.8800e-01, -5.3166e-02,  2.5216e-01,  1.5201e-02,\n",
      "         -1.1768e+00, -7.0560e-01,  2.8999e+00, -1.5287e+00],\n",
      "        [ 1.0944e+00,  7.0499e-01,  9.7460e-01,  4.9916e-01,  2.0788e-01,\n",
      "          5.8160e-01, -5.0269e-01,  3.8249e-01,  3.2186e-01],\n",
      "        [ 1.7331e-03, -5.1617e-01, -7.0694e-01,  1.1713e+00, -7.9562e-02,\n",
      "         -1.5109e+00,  1.1631e+00,  4.9519e-01, -3.5574e-01],\n",
      "        [ 1.4116e+00,  1.4633e+00,  4.0345e-01,  1.2512e+00, -1.2276e-01,\n",
      "          4.1345e-01, -1.1111e+00, -4.1078e-01, -2.2621e-01],\n",
      "        [ 8.4988e-01,  1.8994e-01, -8.2524e-01,  8.1140e-01, -2.8777e-01,\n",
      "          3.2081e-01,  6.4898e-01, -1.9162e-02,  4.6650e-01],\n",
      "        [ 2.1231e-01,  3.6953e-01,  6.8595e-01, -7.2763e-01,  4.1461e-01,\n",
      "         -9.4841e-01, -9.0463e-01,  8.5497e-01, -1.4084e+00],\n",
      "        [-7.6701e-01, -9.0015e-01, -1.8125e-01,  3.7441e-01,  1.7706e-01,\n",
      "          7.8392e-01, -5.9405e-02,  5.8943e-01, -2.0436e+00],\n",
      "        [-2.9112e-01,  1.3911e-01,  9.2465e-01, -9.4520e-01,  5.3497e-01,\n",
      "         -1.1559e+00, -9.0628e-01,  2.2786e-01, -1.9402e-01],\n",
      "        [-7.2730e-01, -1.0409e+00, -9.0912e-01, -8.8691e-01,  3.3333e-01,\n",
      "          1.3989e-02,  2.0093e+00, -1.3294e-01,  4.6581e-01],\n",
      "        [-2.5617e+00,  1.8677e-01, -2.1855e+00, -2.0172e-01, -3.5647e-01,\n",
      "         -1.6537e-01,  4.6342e-01, -1.6505e+00, -4.0047e-01],\n",
      "        [-5.9177e-01,  1.3790e+00,  3.4288e-01, -3.5348e-02, -4.8975e-02,\n",
      "         -1.9386e-01,  6.7304e-01,  1.3066e+00, -3.3615e-01],\n",
      "        [-2.8385e-01, -3.7268e-01,  1.1782e-01, -1.4476e+00,  2.5004e-01,\n",
      "         -2.7805e-01, -7.2893e-01, -2.3644e-01,  2.1698e-01],\n",
      "        [-4.3159e-01, -1.7624e+00, -1.2930e+00,  1.2144e+00,  4.8443e-01,\n",
      "         -1.5179e-01, -2.0105e-01,  1.2147e+00,  3.3847e-01],\n",
      "        [ 1.7563e+00, -3.2169e-01, -1.4715e+00, -2.3867e-01,  1.2333e-01,\n",
      "          1.7102e+00,  7.2393e-01,  1.4080e+00,  2.2154e+00],\n",
      "        [ 2.1613e+00,  1.3372e+00, -1.3547e+00, -2.4939e-01, -1.2396e+00,\n",
      "         -3.1414e-01,  9.6206e-01, -2.3576e+00, -1.5796e+00],\n",
      "        [ 6.5583e-01,  3.1809e-01,  1.3526e+00,  4.6089e-01,  1.8984e+00,\n",
      "         -4.5955e-01, -7.8446e-02, -1.2441e+00, -5.6191e-01],\n",
      "        [-1.1460e+00, -3.3193e-02, -9.8189e-01, -3.0691e-01, -5.2733e-01,\n",
      "         -3.7288e-01,  1.0477e+00,  9.1255e-01, -2.1869e+00],\n",
      "        [ 6.2292e-01, -3.3451e-01, -4.9657e-01, -1.4016e+00,  9.9962e-01,\n",
      "         -1.8684e+00, -1.1324e+00, -7.2509e-01,  4.3776e-01],\n",
      "        [ 5.0424e-01, -1.1501e+00, -6.7531e-01, -3.5404e-01, -6.8959e-02,\n",
      "         -2.6898e-01, -7.2442e-02, -5.0152e-01,  2.7452e+00],\n",
      "        [-6.8684e-01, -7.2486e-01,  4.8877e-02,  4.8962e-02, -2.0403e-01,\n",
      "         -4.1522e-01, -2.8004e-01, -1.6241e+00,  2.9279e-01],\n",
      "        [ 7.1082e-01,  1.0676e-01,  3.1774e-01,  1.5850e+00, -1.5317e+00,\n",
      "          1.3020e+00, -3.5679e-01,  6.4622e-01, -8.9910e-01],\n",
      "        [-1.2266e-01,  1.1718e-01,  8.4409e-02, -5.0715e-01, -7.0887e-01,\n",
      "         -1.6639e-02,  8.9568e-02,  5.1458e-01,  9.4675e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0347, -0.2408,  0.1089,  1.7403, -0.5707,  0.0837,  0.1636,  1.0019,\n",
      "        -0.8968], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"loss backup : \", loss_backup)\n",
    "print(\"----------------\")\n",
    "print(W1_backup)\n",
    "print(b1_backup)\n",
    "print(\"----------------\")\n",
    "print(W2_backup)\n",
    "print(b2_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the model parameters\n",
    "M.W1 = W1_backup\n",
    "M.W2 = W2_backup\n",
    "M.b1 = b1_backup\n",
    "M.b2 = b2_backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose an input \"in the dataset\" for debug visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input  : tensor([0., 0., 0., 1., 0., 0., 1., 0., 0.])\n",
      "target : tensor([2., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "debug output : tensor([  6.1847,   3.5869,   5.3315,  -2.3206, -10.5088,  -5.2965,  -1.8887,\n",
      "          6.5189,  -2.1786,   9.5136,   3.6561,  -9.4451,   2.7971,  -4.7631,\n",
      "          2.4654,   2.2339,   7.2720,  -4.8319,  -5.9096,   2.8287,  -0.0551,\n",
      "          1.6739,   5.6637,   1.4134,  -0.2863, -12.3256,  -3.6353],\n",
      "       grad_fn=<AddBackward0>)\n",
      "\n",
      "debug loss :\t tensor(3.5433, grad_fn=<NllLossBackward0>)\n",
      "W1 grad :\t tensor([[ 0.0000e+00,  1.0799e+00,  4.3889e+00, -1.1989e+00, -1.0318e+00,\n",
      "          0.0000e+00, -2.2258e+00,  2.8811e-01, -3.0002e+00,  1.0454e+00,\n",
      "          2.6131e+00,  8.2442e+00, -5.2789e-01, -6.9018e-01,  1.2503e+00,\n",
      "          1.3180e+00,  5.5312e+00, -1.7584e+00, -1.6998e+00, -5.8338e-01,\n",
      "          1.0824e+01,  5.6999e+00, -1.7084e+00,  3.7661e+00, -5.7395e-01,\n",
      "         -6.0848e-01,  1.9141e+00],\n",
      "        [ 0.0000e+00,  1.0626e+00, -8.0438e-01, -8.4266e-01, -1.7193e-01,\n",
      "         -9.1539e-02, -2.2258e+00,  5.5353e-01,  1.1223e+00,  0.0000e+00,\n",
      "          1.8708e-02,  7.2803e-01, -2.0137e+00,  6.8813e-01,  1.7121e+00,\n",
      "         -3.7169e-01, -1.8710e+00, -8.5111e-02,  2.7375e-01, -1.0791e-01,\n",
      "          1.2773e+00, -6.9414e-01,  0.0000e+00, -1.8569e-01, -2.1428e+00,\n",
      "          9.6101e-01,  2.8630e-01],\n",
      "        [ 0.0000e+00, -1.7307e-02,  1.9896e+00,  3.2100e-01, -9.1394e-01,\n",
      "         -9.1539e-02,  0.0000e+00, -2.6071e-01, -2.8712e+00,  0.0000e+00,\n",
      "          0.0000e+00,  7.2246e+00,  1.3901e+00,  0.0000e+00, -1.3010e+00,\n",
      "          1.4443e+00,  7.1681e+00,  0.0000e+00, -1.7377e-01, -1.8552e+00,\n",
      "          6.2577e+00,  0.0000e+00,  0.0000e+00,  2.8761e+00, -1.8650e+00,\n",
      "         -2.2364e+00,  1.5616e+00],\n",
      "        [ 0.0000e+00, -5.4579e-01,  1.5633e+00,  1.1159e+00,  1.2481e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  2.1144e+00,  0.0000e+00,\n",
      "         -6.6039e-01, -2.1439e+00,  0.0000e+00,  0.0000e+00, -3.8171e+00,\n",
      "          6.1711e-01,  2.3411e-01, -3.5240e-01,  1.3994e+00,  4.1469e+00,\n",
      "         -1.9403e+00,  1.5484e+00,  1.7068e+00,  6.7370e-01,  8.9212e-01,\n",
      "          1.7168e-01, -1.1796e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.4579e-01,  2.0429e+00,  1.1511e+00,  1.6336e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.1615e-03,  1.0454e+00,\n",
      "          2.2894e-01, -7.4078e-01,  0.0000e+00, -1.3783e+00, -1.6436e+00,\n",
      "         -7.6883e-01,  0.0000e+00, -2.2509e+00,  7.4835e-01,  2.3946e+00,\n",
      "         -1.9815e-01,  3.4883e+00, -1.1894e-01,  3.9479e+00, -8.6570e-01,\n",
      "          4.9524e-01, -1.5977e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "\n",
    "src_i = combined_dataloader.dataset.input_tensor[i]\n",
    "trg_i = combined_dataloader.dataset.output_tensor[i]\n",
    "\n",
    "print (\"\\ninput  :\", src_i)\n",
    "print (\"target :\", trg_i)\n",
    "\n",
    "debug_output = M.forward(src_i)\n",
    "print (\"debug output :\", debug_output)\n",
    "\n",
    "# debug_loss = torch.pow(debug_output - trg_i, 2).sum().sqrt()\n",
    "debug_loss = M.crossloss(debug_output, trg_i.argmax(dim=0))\n",
    "print (\"\\ndebug loss :\\t\", debug_loss)\n",
    "\n",
    "debug_loss.backward()\n",
    "print (\"W1 grad :\\t\", M.W1.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of how each function of learning can be simplified to undersand his meanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10.0378,   0.2473,   7.1022, -13.1150,  -8.6392,  -3.1972,   0.4513,\n",
      "           7.0299, -10.9851,   2.0947,  -4.4618, -12.2502,  -4.1681,   0.6682,\n",
      "           3.6768,  -4.6908,  -3.0664,  -5.0941,  -7.5001,  -2.5662,  -3.8774,\n",
      "          -2.3144,   8.4225,  -1.8473,   1.7161, -12.6346,  -1.0849]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (27) must match the size of tensor b (9) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m newoutput \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mforward(src)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(newoutput)\n\u001b[0;32m----> 6\u001b[0m newloss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(\u001b[43mnewoutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(newloss)\n\u001b[1;32m      8\u001b[0m newloss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpow(newoutput \u001b[38;5;241m-\u001b[39m loader\u001b[38;5;241m.\u001b[39mprediction_tensor[i], \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39msqrt()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (27) must match the size of tensor b (9) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    M.W1.grad = M.W1.grad * 0\n",
    "    newoutput = M.forward(src)\n",
    "    print(newoutput)\n",
    "    newloss = torch.abs(newoutput - loader.prediction_tensor[i]).sum()\n",
    "    print(newloss)\n",
    "    newloss = torch.pow(newoutput - loader.prediction_tensor[i], 2).sum().sqrt()\n",
    "    print(newloss)\n",
    "    newloss.backward()\n",
    "    M.W1 -= (M.W1.grad) * 0.0001\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
